{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"border: none\" align=\"left\">\n",
    "   <tr style=\"border: none\">\n",
    "      <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Lab: Build, Save and Deploy a Model to IBM Watson Machine Learning (WML)</b></th>\n",
    "      <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"40\" width=\"40\"></th>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook walks you through these steps:\n",
    "- Build a Spark ML model to predict customer churn\n",
    "- Save the model in the WML repository\n",
    "- Create a Deployment in WML\n",
    "- Invoke the deployed model with a Rest Client to test it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Download the customer churn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run once to install the wget package\n",
    "#!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "url_churn='https://raw.githubusercontent.com/yfphoon/dsx_demo/master/data/customer_churn/churn.csv'\n",
    "url_customer='https://raw.githubusercontent.com/yfphoon/dsx_demo/master/data/customer_churn/customer.csv'\n",
    "\n",
    "#remove existing files before downloading\n",
    "!rm -f churn.csv\n",
    "!rm -f customer.csv\n",
    "\n",
    "churnFilename=wget.download(url_churn)\n",
    "customerFilename=wget.download(url_customer)\n",
    "\n",
    "!ls -l churn.csv\n",
    "!ls -l customer.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create DataFrames with files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "churn = spark.read.format(\"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(churnFilename)\n",
    "customer = spark.read.format(\"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(customerFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Merge Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=customer.join(churn,customer['ID']==churn['ID']).select(customer['*'],churn['CHURN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Rename some columns\n",
    "This step is to remove spaces from columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumnRenamed(\"Est Income\", \"EstIncome\").withColumnRenamed(\"Car Owner\",\"CarOwner\")\n",
    "data.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Build the Spark pipeline and the Random Forest model\n",
    "\"Pipeline\" is an API in SparkML that's used for building models.\n",
    "Additional information on SparkML: https://spark.apache.org/docs/2.0.2/ml-guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer, IndexToString\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# StringIndexer encodes a string column of labels to a column of label indices. \n",
    "SI1 = StringIndexer(inputCol='Gender', outputCol='GenderEncoded')\n",
    "SI2 = StringIndexer(inputCol='Status',outputCol='StatusEncoded')\n",
    "SI3 = StringIndexer(inputCol='CarOwner',outputCol='CarOwnerEncoded')\n",
    "SI4 = StringIndexer(inputCol='Paymethod',outputCol='PaymethodEncoded')\n",
    "SI5 = StringIndexer(inputCol='LocalBilltype',outputCol='LocalBilltypeEncoded')\n",
    "SI6 = StringIndexer(inputCol='LongDistanceBilltype',outputCol='LongDistanceBilltypeEncoded')\n",
    "\n",
    "# Apply OneHotEncoder so categorical features aren't given numeric importance\n",
    "# One-hot encoding maps a column of label indices to a column of binary vectors, with at most a single one-value. \n",
    "OH1 = OneHotEncoder(inputCol=\"GenderEncoded\", outputCol=\"GenderEncoded\"+\"classVec\")\n",
    "OH2 = OneHotEncoder(inputCol=\"StatusEncoded\", outputCol=\"StatusEncoded\"+\"classVec\")\n",
    "OH3 = OneHotEncoder(inputCol=\"CarOwnerEncoded\", outputCol=\"CarOwnerEncoded\"+\"classVec\")\n",
    "OH4 = OneHotEncoder(inputCol=\"PaymethodEncoded\", outputCol=\"PaymethodEncoded\"+\"classVec\")\n",
    "OH5 = OneHotEncoder(inputCol=\"LocalBilltypeEncoded\", outputCol=\"LocalBilltypeEncoded\"+\"classVec\")\n",
    "OH6 = OneHotEncoder(inputCol=\"LongDistanceBilltypeEncoded\", outputCol=\"LongDistanceBilltypeEncoded\"+\"classVec\")\n",
    "\n",
    "\n",
    "# Pipelines API requires that input variables are passed in  a vector\n",
    "assembler = VectorAssembler(inputCols=[\"GenderEncodedclassVec\", \"StatusEncodedclassVec\", \"CarOwnerEncodedclassVec\", \"PaymethodEncodedclassVec\", \"LocalBilltypeEncodedclassVec\", \\\n",
    "                                       \"LongDistanceBilltypeEncodedclassVec\", \"Children\", \"EstIncome\", \"Age\", \"LongDistance\", \"International\", \"Local\",\\\n",
    "                                      \"Dropped\",\"Usage\",\"RatePlan\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode the label column\n",
    "labelIndexer = StringIndexer(inputCol='CHURN', outputCol='label').fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the algorithm, take the default settings\n",
    "rf=RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the pipeline\n",
    "pipeline = Pipeline(stages=[SI1,SI2,SI3,SI4,SI5,SI6, labelIndexer, OH1, OH2, OH3, OH4, OH5, OH6, assembler, rf, labelConverter])# Split data into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test datasets\n",
    "(trainingData, testingData) = data.randomSplit([0.7, 0.3],seed=9)\n",
    "trainingData.cache()\n",
    "testingData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build model. The fitted model from a Pipeline is a PipelineModel, which consists of fitted models and transformers, corresponding to the pipeline stages.\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 6: Score the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = model.transform(testingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Precision model1 = {:.2f}.'.format(results.filter(results.label == results.prediction).count() / float(results.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "print 'Area under ROC curve = {:.2f}.'.format(evaluator.evaluate(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Save Model in WML repository\n",
    "\n",
    "In this section you will store your model in the Watson Machine Learning (WML) repository by using Python client libraries.\n",
    "* <a href=\"https://console.ng.bluemix.net/docs/services/PredictiveModeling/index.html\">WML Documentation</a>\n",
    "* <a href=\"http://watson-ml-api.mybluemix.net/\">WML REST API</a> \n",
    "* <a href=\"https://watson-ml-staging-libs.mybluemix.net/repository-python/\">WML Repository API</a>\n",
    "<br/>\n",
    "\n",
    "First, you must import client libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from repository.mlrepositoryclient import MLRepositoryClient\n",
    "from repository.mlrepositoryartifact import MLRepositoryArtifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your authentication information from your instance of the Watson Machine Learning service in <a href=\"https://console.ng.bluemix.net/dashboard/apps/\" target=\"_blank\">Bluemix</a> in the next cell. You can find your information in the **Service Credentials** tab of your service instance in Bluemix.\n",
    "\n",
    "![WML Credentials](https://raw.githubusercontent.com/yfphoon/IntroToWML/master/images/WML%20Credentials.png)\n",
    "\n",
    "<span style=\"color:red\">Replace the service_path and credentials with your own information</span>\n",
    "\n",
    "service_path=[your url]<br/>\n",
    "instance_id=[your instance_id]<br/>\n",
    "username=[your username]<br/>\n",
    "password=[your password]<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "service_path = 'https://ibm-watson-ml.mybluemix.net'\n",
    "\n",
    "# instance_id not needed for this lab. Left here for future improvement of the lab. No need to update this field.\n",
    "instance_id = 'fd6f82de-d104-4e02-a328-73fd8adfed96'\n",
    "\n",
    "username = 'XXXXX'\n",
    "password = 'XXXXX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authorize the repository client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_repository_client = MLRepositoryClient(service_path)\n",
    "ml_repository_client.authorize(username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model artifact.\n",
    "\n",
    "<b>Tip:</b> The MLRepositoryArtifact method expects a trained model object, training data, and a model name. (It is this model name that is displayed by the Watson Machine Learning service).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_artifact = MLRepositoryArtifact(model, training_data=trainingData, name=\"Predict Customer Churn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model artifact to your Watson Machine Learning instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved_model = ml_repository_client.models.save(model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the saved model properties\n",
    "print \"modelType: \" + saved_model.meta.prop(\"modelType\")\n",
    "print \"creationTime: \" + str(saved_model.meta.prop(\"creationTime\"))\n",
    "print \"modelVersionHref: \" + saved_model.meta.prop(\"modelVersionHref\")\n",
    "print \"label: \" + saved_model.meta.prop(\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Generate the Authorization Token for Invoking the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib3, requests, json\n",
    "\n",
    "headers = urllib3.util.make_headers(basic_auth='{}:{}'.format(username, password))\n",
    "url = '{}/v2/identity/token'.format(service_path)\n",
    "response = requests.get(url, headers=headers)\n",
    "mltoken = json.loads(response.text).get('token')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10:  Go to WML in Bluemix to create a Deployment Endpoint\n",
    "\n",
    "* In your <a href=\"https://console.ng.bluemix.net/dashboard/apps/\" target=\"_blank\">Bluemix</a> dashboard, click into your WML Service and click the **Launch Dashboard** button under Watson Machine Learing.\n",
    "![WML Launch Dashboard](https://raw.githubusercontent.com/DScienceAtScale/DSX/master/PredictCustomerChurn/Images/WML_Launch_Dashboard.png)\n",
    "\n",
    "<br/>\n",
    "* You should see your saved model in the **Models** tab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Under *Actions*, click on the 3 ellipses and click ***Create Deployment***.  Give your deployment configuration a unique name, e.g. \"Predict Customer Churn Deply\", select Type=Online and click **Save**.\n",
    "<br/>\n",
    "<br/>\n",
    "* In the *Deployments tab*, under *Actions*, click **View Details**\n",
    "<br/>\n",
    "<br/>\n",
    "* Scoll down to **API Details**, copy the value of the **Scoring Endpoint** into your notepad.  (e.g. \thttps://ibm-watson-ml.mybluemix.net/v2/published_models/64fd0462-3f8a-4b42-820b-59a4da9b7dc6/deployments/7d9995ed-7daf-4cfd-b40f-37cb8ab3d88f/online)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11:  Invoke the model through REST API call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a JSON Sample record for the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_data = {\n",
    "    \"fields\": [\n",
    "    \"ID\",\n",
    "    \"Gender\",\n",
    "    \"Status\",\n",
    "    \"Children\",\n",
    "    \"EstIncome\",\n",
    "    \"CarOwner\",\n",
    "    \"Age\",\n",
    "    \"LongDistance\",\n",
    "    \"International\",\n",
    "    \"Local\",\n",
    "    \"Dropped\",\n",
    "    \"Paymethod\",\n",
    "    \"LocalBilltype\",\n",
    "    \"LongDistanceBilltype\",\n",
    "    \"Usage\",\n",
    "    \"RatePlan\"\n",
    "    ],\n",
    "    \"values\": [ [999,\"F\",\"M\",2.0,77551.100000,\"Y\",33.600000,20.530000,0.000000,41.890000,1.000000,\"CC\",\"Budget\",\"Intnl_discount\",62.420000,2.000000] ]\n",
    "} \n",
    "\n",
    "sample_json = json.dumps(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: Call the REST API Programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the scoring endpoint from the WML service\n",
    "churnModel_endpoint = 'https://ibm-watson-ml.mybluemix.net/v3/wml_instances/b97ea195-286e-4251-8424-fe7655b4e099/published_models/72df382c-910a-481a-8822-df34875e9554/deployments/65a27a4b-a788-4b57-a760-4a7ffc3fe3d9/online'\n",
    "header_online = {'Content-Type': 'application/json', 'Authorization': 'Bearer' + mltoken}\n",
    "\n",
    "# API call here\n",
    "response_scoring = requests.post(churnModel_endpoint, data=sample_json, headers=header_online)\n",
    "\n",
    "print response_scoring.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab Predicted Value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml = json.loads(response_scoring.text)\n",
    "\n",
    "# First zip the fields and values together\n",
    "zipped_wml = zip(wml['fields'], wml['values'].pop())\n",
    "\n",
    "# Next iterate through items and grab the prediction value\n",
    "[v for (k,v) in zipped_wml if k == 'prediction'].pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Call the REST API through a REST Client, e.g. https://client.restlet.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the Authorization token\n",
    "print(mltoken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the REST client interface enter the following information:\n",
    "\n",
    "1. Protocol:  **HTTPS**\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "2. URI: **your scoring endpoint**  (Step 10)\n",
    "<br/>\n",
    "<br/>\n",
    "3. method: **POST**\n",
    "<br/>\n",
    "<br/>\n",
    "4. Authorization:  **your generated token**. **Hint**: Add \"Basic authorization\" with a dummy value of 1 in the userid field. Then replace the value with the token. \n",
    "<br/>\n",
    "<br/>\n",
    "5. Content Type: **application/JSON**\n",
    "<br/>\n",
    "<br/>\n",
    "6. JSON Body:<br/>**{\n",
    "  \"fields\": [\n",
    "    \"ID\",\"Gender\",\"Status\",\"Children\",\"EstIncome\",\"CarOwner\",\"Age\",\"LongDistance\",\"International\",\"Local\",\"Dropped\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\",\"Usage\",\"RatePlan\"\n",
    "  ],\n",
    "  \"values\": [ \n",
    "  [999,\"F\",\"M\",2.0,77551.100000,\"Y\",33.600000,20.530000,0.000000,41.890000,1.000000,\"CC\",\"Budget\",\"Intnl_discount\",62.420000,2.000000]\n",
    "  ]\n",
    "} **\n",
    "<br/>\n",
    "<br/>\n",
    "7. Click **Send*\n",
    "\n",
    "Scroll down to the **RESPONSE** section to see the scored results\n",
    "\n",
    "**Note:** The values in the JSON body does not include the label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample REST Client Input**\n",
    "![Rest Client Input](https://github.com/ibm-cloud-architecture/refarch-data-science/blob/master/static/imgs/RestRequest.PNG?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You have come to the end of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Sidney Phoon**\n",
    "<br/>\n",
    "yfphoon@us.ibm.com\n",
    "<br/>\n",
    "August 11, 2017"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.0",
   "language": "python",
   "name": "python2-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
